# 前言
## 数据
- 与传统机器学习方法相比，深度学习的一个主要优势是可以处理不同长度的数据；
- 当我们有了更多的数据，我们通常可以训练出更强大的模型，从而减少对预先设想假设的依赖；
- 仅仅拥有海量的数据是不够的，我们还需要正确的数据。
## 模型
- 深度学习与经典方法的区别主要在于：前者关注的功能强大的模型，这些模型由神经网络错综复杂的交织在一起，包含层层数据转换，因此被称为深度学习（deep learning）。
## 目标函数
- 在机器学习中，我们需要定义模型的优劣程度的度量，这个度量在大多数情况是“可优化”的，我们称之为目标函数（objective function）。 我们通常定义一个目标函数，并希望优化它到最低点。 因为越低越好，所以这些函数有时被称为损失函数（loss function，或cost function）。
## 优化算法
- 深度学习中，大多流行的优化算法通常基于一种基本方法–梯度下降（gradient descent）；
- 在可以减少损失的方向上优化参数。
## 各种机器学习问题
### 监督学习
监督学习（supervised learning）擅长在“给定输入特征”的情况下预测标签。
#### 回归
总而言之，判断回归问题的一个很好的经验法则是，任何有关“多少”的问题很可能就是回归问题。
#### 分类
在分类问题中，我们希望模型能够预测样本属于哪个类别（category，正式称为类（class））。
#### 推荐系统
它的目标是向特定用户进行“个性化”推荐。
### 无监督学习

